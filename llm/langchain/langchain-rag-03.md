# **LangChain RAGè¬›åº§ ç¬¬3å›ï¼šRAGã®ç²¾åº¦å‘ä¸Šãƒ†ã‚¯ãƒ‹ãƒƒã‚¯**

## **1. ã¯ã˜ã‚ã«**

çš†ã•ã‚“ã€ã“ã‚“ã«ã¡ã¯ï¼LangChainã‚’ç”¨ã„ãŸRAGé–‹ç™ºè¬›åº§ã®ç¬¬3å›ã¸ã‚ˆã†ã“ãã€‚

ã“ã‚Œã¾ã§ã®æˆæ¥­ã§ã¯ã€LangChainã‚’ä½¿ã£ã¦åŸºæœ¬çš„ãªRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•ã‚’å­¦ã‚“ã§ãã¾ã—ãŸã€‚ä»Šå›ã¯ã€ãã®**æ¤œç´¢ç²¾åº¦ã‚’ã•ã‚‰ã«å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®é«˜åº¦ãªæ¤œç´¢æ‰‹æ³•**ã«ç„¦ç‚¹ã‚’å½“ã¦ã€ãƒãƒ³ã‚ºã‚ªãƒ³å½¢å¼ã§å­¦ã‚“ã§ã„ãã¾ã™ã€‚

æœ¬è³‡æ–™ã¯ã€ã¾ãš**åŸºæœ¬çš„ãªRAGã®å®Œå…¨ãªã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰**ã‚’ç¤ºã—ã€ãã®å‹•ä½œã‚’ç¢ºèªã—ã¾ã™ã€‚ãã®å¾Œã€å¿œç”¨ã¨ã—ã¦ä»¥ä¸‹ã®3ã¤ã®é«˜åº¦ãªæ¤œç´¢æ‰‹æ³•ã‚’ã€ãã‚Œãã‚Œç‹¬ç«‹ã—ãŸã‚³ãƒ¼ãƒ‰ã§è©¦ã—ã¦ã„ãã¾ã™ã€‚

* **Multi-Query Retriever**: æ¤œç´¢æ¼ã‚Œã‚’æ¸›ã‚‰ã™è³¢ã„è³ªå•ç”Ÿæˆ  
* **Hybrid Search**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨æ„å‘³ã®ã€Œã„ã„ã¨ã“å–ã‚Šã€æ¤œç´¢  
* **Re-ranking**: æ¤œç´¢çµæœã‚’ã•ã‚‰ã«ç£¨ãä¸Šã’ã‚‹ä¸¦ã¹æ›¿ãˆ

ãã‚Œã§ã¯ã€ã•ã£ããå§‹ã‚ã¦ã„ãã¾ã—ã‚‡ã†ï¼ğŸš€

## **2. æº–å‚™**

ã¾ãšã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«PCã®VSCodeç’°å¢ƒã§ãƒãƒ³ã‚ºã‚ªãƒ³ã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã€APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¾ã—ã‚‡ã†ã€‚

### **2.1. ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã«ç’°å¢ƒã‚’åˆ†é›¢ã™ã‚‹ãŸã‚ã€ä»®æƒ³ç’°å¢ƒã®ä½œæˆã‚’å¼·ãæ¨å¥¨ã—ã¾ã™ã€‚ä»¥ä¸‹ã®æ‰‹é †ã«å¾“ã£ã¦ã€ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚

1. **VSCodeã§ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’é–‹ã**:  
   * VSCodeã®ä¸Šéƒ¨ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ ã‚¿ãƒ¼ãƒŸãƒŠãƒ« > æ–°ã—ã„ã‚¿ãƒ¼ãƒŸãƒŠãƒ« ã‚’é¸æŠã—ã€ç”»é¢ä¸‹éƒ¨ã«ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚’é–‹ãã¾ã™ã€‚  
2. **ä»®æƒ³ç’°å¢ƒã®ä½œæˆ**:  
   * é–‹ã„ãŸã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦.venvã¨ã„ã†åå‰ã®ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¾ã™ã€‚

python -m venv .venv

3. **ä»®æƒ³ç’°å¢ƒã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆ**:  
   * ãŠä½¿ã„ã®OSã«å¿œã˜ã¦ã€ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ä»®æƒ³ç’°å¢ƒã‚’æœ‰åŠ¹ã«ã—ã¾ã™ã€‚  
   * **Windowsã®å ´åˆ (PowerShell):**  
     .venvScriptsActivate.ps1

   * **macOS / Linuxã®å ´åˆ:**  
     source .venv/bin/activate

   * æˆåŠŸã™ã‚‹ã¨ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã®è¡Œé ­ã« (.venv) ã®ã‚ˆã†ãªè¡¨ç¤ºãŒè¿½åŠ ã•ã‚Œã¾ã™ã€‚  
4. **ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**:  
   * ã‚¢ã‚¯ãƒ†ã‚£ãƒ™ãƒ¼ãƒˆã•ã‚ŒãŸã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ã€å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã™ã¹ã¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚

pip install langchain langchain-openai langchain-community chromadb sentence-transformers tiktoken rank_bm25 python-dotenv

### **2.2. APIã‚­ãƒ¼ã®è¨­å®š**

ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§å®‰å…¨ã«APIã‚­ãƒ¼ã‚’ç®¡ç†ã™ã‚‹ãŸã‚ã€.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

1. **.envãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ**: VSCodeã®ã‚¨ã‚¯ã‚¹ãƒ—ãƒ­ãƒ¼ãƒ©ãƒ¼ã§ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã« .env ã¨ã„ã†åå‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–°è¦ä½œæˆã—ã¾ã™ã€‚  
2. **APIã‚­ãƒ¼ã®è¨˜è¿°**: ä½œæˆã—ãŸ.envãƒ•ã‚¡ã‚¤ãƒ«ã«ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ã”è‡ªèº«ã®**OpenRouterã®APIã‚­ãƒ¼**ã‚’è¨˜è¿°ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚ã“ã®ã‚­ãƒ¼ã¯LLMï¼ˆæ–‡ç« ç”Ÿæˆï¼‰ã®å‘¼ã³å‡ºã—ã«ä½¿ç”¨ã—ã¾ã™ã€‚  
   OPENROUTER_API_KEY="sk-or-v1-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

## **3. åŸºæœ¬çš„ãªRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè£…ã¨å®Ÿè¡Œ**

æœ€åˆã«ã€RAGã®åŸºæœ¬ã¨ãªã‚‹ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Œå…¨ãªã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’è¦‹ã¦ã„ãã¾ã—ã‚‡ã†ã€‚ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãã‚Œã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ä¿å­˜ã—ã€è³ªå•å¿œç­”ã‚’è¡Œã†ã¾ã§ã®ä¸€é€£ã®æµã‚Œã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚

### **3.1. å®Œå…¨ãªã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ (åŸºæœ¬å½¢)**

ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚’ basic_rag.py ã®ã‚ˆã†ãªåå‰ã§ä¿å­˜ã—ã¦ãã ã•ã„ã€‚
```python
import os  
from dotenv import load_dotenv  
from langchain_openai import ChatOpenAI  
from langchain_community.embeddings import HuggingFaceEmbeddings  
from langchain_community.document_loaders import TextLoader  
from langchain.text_splitter import RecursiveCharacterTextSplitter  
from langchain_community.vectorstores import Chroma  
from langchain.chains import RetrievalQA

def main():  
    # --- 1. æº–å‚™ ---  
    # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã¿  
    load_dotenv()  
      
    # OpenRouterã®APIã‚­ãƒ¼ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—  
    openrouter_api_key = os.getenv("OPENROUTER_API_KEY")  
    if not openrouter_api_key:  
        print("OPENROUTER_API_KEYãŒ.envãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")  
        return

    print(f"èª­ã¿è¾¼ã¾ã‚ŒãŸOpenRouter APIã‚­ãƒ¼ã®æœ«å°¾5æ–‡å­—: ...{openrouter_api_key[-5:]}")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æº–å‚™  
    sample_text = """  
Geminiã¯ã€Googleã«ã‚ˆã£ã¦é–‹ç™ºã•ã‚ŒãŸãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«AIãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚  
ãƒ†ã‚­ã‚¹ãƒˆã€ç”»åƒã€éŸ³å£°ã€å‹•ç”»ãªã©ã€ã•ã¾ã–ã¾ãªç¨®é¡ã®æƒ…å ±ã‚’çµ±åˆçš„ã«å‡¦ç†ã§ãã¾ã™ã€‚  
Geminiã«ã¯ã€èƒ½åŠ›ã«å¿œã˜ã¦Ultraã€Proã€Nanoã®3ã¤ã®ã‚µã‚¤ã‚ºãŒã‚ã‚Šã¾ã™ã€‚

Gemini Ultraã¯ã€éå¸¸ã«è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã§ãã‚‹ã€æœ€ã‚‚é«˜æ€§èƒ½ãªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚  
ãã®èƒ½åŠ›ã¯ã€MMLUï¼ˆMassive Multitask Language Understandingï¼‰ã¨å‘¼ã°ã‚Œã‚‹ã€  
å°‚é–€å®¶ãƒ¬ãƒ™ãƒ«ã®çŸ¥è­˜ã‚’æ¸¬å®šã™ã‚‹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã§ã€äººé–“ã®å°‚é–€å®¶ã‚’ä¸Šå›ã‚‹ã‚¹ã‚³ã‚¢ã‚’è¨˜éŒ²ã—ãŸåˆã®ãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦çŸ¥ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚  
ä¸»ã«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒ³ã‚¿ãƒ¼ã‚„ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºå‘ã‘ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§åˆ©ç”¨ã•ã‚Œã‚‹ã“ã¨ãŒæƒ³å®šã•ã‚Œã¦ã„ã¾ã™ã€‚

Gemini Proã¯ã€å¹…åºƒã„ã‚¿ã‚¹ã‚¯ã«å¯¾å¿œã§ãã‚‹ã€æ±ç”¨æ€§ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚  
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚³ã‚¹ãƒˆã®ãƒãƒ©ãƒ³ã‚¹ã«å„ªã‚Œã¦ãŠã‚Šã€Google AI Studioã‚„Google Cloud Vertex AIã‚’é€šã˜ã¦åˆ©ç”¨ã§ãã¾ã™ã€‚  
å¤šãã®é–‹ç™ºè€…ãŒåˆ©ç”¨ã™ã‚‹ã§ã‚ã‚ã†ä¸»è¦ãªãƒ¢ãƒ‡ãƒ«ã¨ä½ç½®ã¥ã‘ã‚‰ã‚Œã¦ã„ã¾ã™ã€‚

Gemini Nanoã¯ã€ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ãªã©ã®ã‚ªãƒ³ãƒ‡ãƒã‚¤ã‚¹ç’°å¢ƒã§åŠ¹ç‡çš„ã«å‹•ä½œã™ã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚ŒãŸã€æœ€ã‚‚è»½é‡ãªãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚  
ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šãŒãªã„çŠ¶æ³ã§ã‚‚ã€è¦ç´„ã‚„ç¿»è¨³ãªã©ã®ã‚¿ã‚¹ã‚¯ã‚’é«˜é€Ÿã«å®Ÿè¡Œã§ãã¾ã™ã€‚  
Androidã‚¢ãƒ—ãƒªã¸ã®çµ„ã¿è¾¼ã¿ãªã©ãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚

ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€Googleã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆã€ä¾‹ãˆã°æ¤œç´¢ã‚„åºƒå‘Šã€Chromeã€Bardï¼ˆç¾Geminiï¼‰ãªã©ã«é †æ¬¡çµ±åˆã•ã‚Œã¦ã„ã¾ã™ã€‚  
é–‹ç™ºè€…ã¯ã€Google AI Studioã‚„Vertex AIã®APIã‚’é€šã˜ã¦ã€Gemini Proã‚’åˆ©ç”¨ã—ãŸã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚  
"""  
    with open("gemini_document.txt", "w", encoding="utf-8") as f:  
        f.write(sample_text)

    # --- 2. åŸºæœ¬çš„ãªRAGãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ ---  
    # LLM (OpenRouterçµŒç”±)  
    llm = ChatOpenAI(  
        model="google/gemma-3-12b-it:free",  
        temperature=0,  
        base_url="https://openrouter.ai/api/v1",  
        api_key=openrouter_api_key  
    )  
    # Embedding (ãƒ­ãƒ¼ã‚«ãƒ«ã®HuggingFaceãƒ¢ãƒ‡ãƒ«)  
    # åˆå›å®Ÿè¡Œæ™‚ã«ãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒè‡ªå‹•çš„ã«è¡Œã‚ã‚Œã¾ã™ã€‚  
    print("Embeddingãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")  
    embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")  
    print("Embeddingãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®èª­ã¿è¾¼ã¿ã€åˆ†å‰²  
    loader = TextLoader("gemini_document.txt", encoding="utf-8")  
    documents = loader.load()  
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)  
    texts = text_splitter.split_documents(documents)

    # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢(Chroma)ã®ä½œæˆ  
    print("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã¦ã„ã¾ã™...")  
    vectorstore = Chroma.from_documents(texts, embeddings)  
    print("ãƒ™ã‚¯ãƒˆãƒ«åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

    # QAãƒã‚§ãƒ¼ãƒ³ã®ä½œæˆ  
    base_qa_chain = RetrievalQA.from_chain_type(  
        llm=llm,  
        chain_type="stuff",  
        retriever=vectorstore.as_retriever()  
    )

    # --- 3. å®Ÿè¡Œ ---  
    question = "Gemini Proã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚"  
    print(f"\nè³ªå•: {question}")  
    response = base_qa_chain.invoke(question)  
    print(f"å›ç­”: {response['result']}")

if __name__ == "__main__":  
    main()
```
### **3.2. å®Ÿè¡Œæ–¹æ³•**

1. ä¸Šè¨˜ã®ã‚³ãƒ¼ãƒ‰ã‚’ basic_rag.py ã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚  
2. .env ãƒ•ã‚¡ã‚¤ãƒ«ã« OPENROUTER_API_KEY ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ã€‚  
3. VSCodeã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚  
   python basic_rag.py

4. åˆå›å®Ÿè¡Œæ™‚ã«ã¯ã€Embeddingãƒ¢ãƒ‡ãƒ«ï¼ˆintfloat/multilingual-e5-largeï¼‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒè¡Œã‚ã‚Œã‚‹ãŸã‚ã€å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚  
5. å®Ÿè¡Œçµæœã¨ã—ã¦ã€ã¾ãšAPIã‚­ãƒ¼ã®æœ«å°¾5æ–‡å­—ãŒè¡¨ç¤ºã•ã‚Œã€ãã®å¾Œã«è³ªå•ã¸ã®å›ç­”ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

## **4. é«˜åº¦ãªæ¤œç´¢æ‰‹æ³•**

åŸºæœ¬ã®RAGãŒå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã§ããŸã‚‰ã€æ¬¡ã«å¿œç”¨ã¨ã—ã¦æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹3ã¤ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’è©¦ã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚

### **4.1. Multi-Query Retriever**

#### **è§£èª¬**

ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®1ã¤ã®è³ªå•ã‚’ã€LLMã‚’ä½¿ã£ã¦è¤‡æ•°ã®ç•°ãªã‚‹è¦–ç‚¹ã‹ã‚‰ã®è³ªå•ã«è‡ªå‹•çš„ã«æ›¸ãæ›ãˆã‚‹MultiQueryRetrieverã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚

* **ã‚¢ã‚¤ãƒ‡ã‚¢**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ãŒæ›–æ˜§ã ã£ãŸã‚Šã€è¡¨ç¾ãŒä¸€ã¤ã—ã‹ãªã„å ´åˆã€é–¢é€£ã™ã‚‹æƒ…å ±ã‚’è¦‹é€ƒã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãã“ã§ã€LLMã«ã€Œã“ã®è³ªå•ã¯ã€åˆ¥ã®è¨€ã„æ–¹ã‚’ã™ã‚‹ã¨ã©ã†ãªã‚‹ï¼Ÿã€ã¨è€ƒãˆã•ã›ã€ç”Ÿæˆã•ã‚ŒãŸè¤‡æ•°ã®è³ªå•ã§æ¤œç´¢ã‚’ã‹ã‘ã‚‹ã“ã¨ã§ã€æ¤œç´¢ç¯„å›²ã‚’åºƒã’ã€æƒ…å ±ã®è¦‹é€ƒã—ã‚’æ¸›ã‚‰ã—ã¾ã™ã€‚  
* **ã‚³ãƒ¼ãƒ‰ã®ãƒã‚¤ãƒ³ãƒˆ**:  
  * MultiQueryRetriever.from_llm(): ã“ã®é–¢æ•°ã§ã€åŸºæœ¬çš„ãªãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ï¼ˆbase_retrieverï¼‰ã¨ã€è³ªå•ã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã®LLMï¼ˆllmï¼‰ã‚’æ¸¡ã™ã ã‘ã§ã€ç°¡å˜ã«Multi-Query Retrieverã‚’ä½œæˆã§ãã¾ã™ã€‚  
  * logging.basicConfig(...): ãƒ­ã‚°å‡ºåŠ›ã‚’æœ‰åŠ¹ã«ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‚’è¨­å®šã™ã‚‹ã¨ã€LLMãŒã©ã®ã‚ˆã†ãªè³ªå•ã‚’æ–°ãŸã«ç”Ÿæˆã—ãŸã‹ãŒã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«è¡¨ç¤ºã•ã‚Œã‚‹ãŸã‚ã€è£å´ã§ä½•ãŒèµ·ãã¦ã„ã‚‹ã‹ã‚’ç†è§£ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚

#### **ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ (multi_query_rag.py)**
```python
import os  
import logging  
from dotenv import load_dotenv  
from langchain_openai import ChatOpenAI  
from langchain_community.embeddings import HuggingFaceEmbeddings  
from langchain_community.document_loaders import TextLoader  
from langchain.text_splitter import RecursiveCharacterTextSplitter  
from langchain_community.vectorstores import Chroma  
from langchain.chains import RetrievalQA  
from langchain.retrievers.multi_query import MultiQueryRetriever

logging.basicConfig(level=logging.INFO)  
logging.getLogger("langchain.retrievers.multi_query").setLevel(logging.INFO)

def main():  
    # --- æº–å‚™ ---  
    load_dotenv()  
    openrouter_api_key = os.getenv("OPENROUTER_API_KEY")  
    if not openrouter_api_key:  
        print("OPENROUTER_API_KEYãŒ.envãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")  
        return  
    print(f"èª­ã¿è¾¼ã¾ã‚ŒãŸOpenRouter APIã‚­ãƒ¼ã®æœ«å°¾5æ–‡å­—: ...{openrouter_api_key[-5:]}")

    llm = ChatOpenAI(model="google/gemma-3-12b-it:free", temperature=0, base_url="https://openrouter.ai/api/v1", api_key=openrouter_api_key)  
    embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")  
      
    loader = TextLoader("gemini_document.txt", encoding="utf-8")  
    documents = loader.load()  
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)  
    texts = text_splitter.split_documents(documents)  
    vectorstore = Chroma.from_documents(texts, embeddings)  
    base_retriever = vectorstore.as_retriever()

    # --- Multi-Query Retrieverã‚’ä½¿ã£ãŸQAãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰ ---  
    multi_query_retriever = MultiQueryRetriever.from_llm(retriever=base_retriever, llm=llm)  
    qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=multi_query_retriever)

    # --- å®Ÿè¡Œ ---  
    question = "ä¸€ç•ªå°ã•ã„Geminiãƒ¢ãƒ‡ãƒ«ã«ã¤ã„ã¦æ•™ãˆã¦"  
    print(f"\nè³ªå•: {question}")  
    response = qa_chain.invoke(question)  
    print(f"å›ç­”: {response['result']}")

if __name__ == "__main__":  
    main()
```
### **4.2. Hybrid Search (EnsembleRetriever)**

#### **è§£èª¬**

ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ã€Œãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã€ã‚’å®Ÿç¾ã™ã‚‹EnsembleRetrieverã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã¯ã€æ€§è³ªã®ç•°ãªã‚‹2ã¤ã®æ¤œç´¢æ–¹æ³•ã‚’çµ„ã¿åˆã‚ã›ã‚‹ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã§ã™ã€‚

* **ã‚¢ã‚¤ãƒ‡ã‚¢**: ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ï¼ˆæ„å‘³ã®è¿‘ã•ã§æ¤œç´¢ï¼‰ã¯æ–‡è„ˆã‚’æ‰ãˆã‚‹ã®ãŒå¾—æ„ã§ã™ãŒã€å°‚é–€ç”¨èªã‚„å›ºæœ‰åè©ãªã©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ä¸€è‡´ã‚’è¦‹é€ƒã™ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ä¸€æ–¹ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ï¼ˆBM25ï¼‰ã¯ãã®é€†ã§ã™ã€‚EnsembleRetrieverã¯ã€ã“ã®2ã¤ã®ã€Œã„ã„ã¨ã“å–ã‚Šã€ã‚’ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šé ‘å¥ãªæ¤œç´¢ã‚’å®Ÿç¾ã—ã¾ã™ã€‚  
* **ã‚³ãƒ¼ãƒ‰ã®ãƒã‚¤ãƒ³ãƒˆ**:  
  * BM25Retriever: ä¼çµ±çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚from_documents()ã§ç°¡å˜ã«ä½œæˆã§ãã¾ã™ã€‚  
  * EnsembleRetriever: retrieverså¼•æ•°ã«ã€çµ„ã¿åˆã‚ã›ãŸã„ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã®ãƒªã‚¹ãƒˆï¼ˆä»Šå›ã¯BM25ã¨Chromaï¼‰ã‚’æ¸¡ã—ã¾ã™ã€‚weightså¼•æ•°ã§ã€ãã‚Œãã‚Œã®æ¤œç´¢çµæœã‚’ã©ã®ãã‚‰ã„ã®é‡ã¿ã§è©•ä¾¡ã™ã‚‹ã‹ã‚’æŒ‡å®šã§ãã¾ã™ï¼ˆä¾‹: [0.5, 0.5]ãªã‚‰å‡ç­‰ï¼‰ã€‚

#### **ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ (hybrid_search_rag.py)**
```
import os  
from dotenv import load_dotenv  
from langchain_openai import ChatOpenAI  
from langchain_community.embeddings import HuggingFaceEmbeddings  
from langchain_community.document_loaders import TextLoader  
from langchain.text_splitter import RecursiveCharacterTextSplitter  
from langchain_community.vectorstores import Chroma  
from langchain.chains import RetrievalQA  
from langchain.retrievers import BM25Retriever, EnsembleRetriever

def main():  
    # --- æº–å‚™ ---  
    load_dotenv()  
    openrouter_api_key = os.getenv("OPENROUTER_API_KEY")  
    if not openrouter_api_key:  
        print("OPENROUTER_API_KEYãŒ.envãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")  
        return  
    print(f"èª­ã¿è¾¼ã¾ã‚ŒãŸOpenRouter APIã‚­ãƒ¼ã®æœ«å°¾5æ–‡å­—: ...{openrouter_api_key[-5:]}")

    llm = ChatOpenAI(model="google/gemma-3-12b-it:free", temperature=0, base_url="https://openrouter.ai/api/v1", api_key=openrouter_api_key)  
    embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")

    loader = TextLoader("gemini_document.txt", encoding="utf-8")  
    documents = loader.load()  
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)  
    texts = text_splitter.split_documents(documents)  
    vectorstore = Chroma.from_documents(texts, embeddings)

    # --- Hybrid Search (EnsembleRetriever)ã‚’ä½¿ã£ãŸQAãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰ ---  
    bm25_retriever = BM25Retriever.from_documents(texts)  
    bm25_retriever.k = 2  
    chroma_retriever = vectorstore.as_retriever(search_kwargs={"k": 2})  
    ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, chroma_retriever], weights=[0.5, 0.5])  
    qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=ensemble_retriever)

    # --- å®Ÿè¡Œ ---  
    question = "MMLUã§é«˜ã„ã‚¹ã‚³ã‚¢ã‚’å‡ºã—ãŸãƒ¢ãƒ‡ãƒ«ã¯ä½•ã§ã™ã‹ï¼Ÿ"  
    print(f"\nè³ªå•: {question}")  
    response = qa_chain.invoke(question)  
    print(f"å›ç­”: {response['result']}")

if __name__ == "__main__":  
    main()
```
### **4.3. Re-ranking**

#### **è§£èª¬**

ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€å–å¾—ã—ãŸæ¤œç´¢çµæœã‚’ã‚ˆã‚Šç²¾åº¦ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ã§ä¸¦ã¹æ›¿ãˆã‚‹ã€ŒRe-rankingï¼ˆãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰ã€ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚

* **ã‚¢ã‚¤ãƒ‡ã‚¢**: æœ€åˆã®æ¤œç´¢ï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ãªã©ï¼‰ã¯é«˜é€Ÿã§ã™ãŒã€å®Œå…¨ã«é–¢é€£æ€§ã®é«˜ã„é †ã«ä¸¦ã‚“ã§ã„ã‚‹ã¨ã¯é™ã‚Šã¾ã›ã‚“ã€‚ãã“ã§ã€ã¾ãšå¤§ã¾ã‹ã«é–¢é€£ã—ãã†ãªæ–‡æ›¸ã‚’å¤šã‚ã«å–å¾—ã—ï¼ˆ1æ®µéšç›®ï¼‰ã€ãã®å¾Œã€ã‚ˆã‚Šç²¾å¯†ãªã€Œã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã€ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€è³ªå•ã¨å„æ–‡æ›¸ã®é–¢é€£åº¦ã‚’å†è¨ˆç®—ã—ã€æœ¬å½“ã«é‡è¦ãªæ–‡æ›¸ã ã‘ã‚’å³é¸ã—ã¾ã™ï¼ˆ2æ®µéšç›®ï¼‰ã€‚  
* **ã‚³ãƒ¼ãƒ‰ã®ãƒã‚¤ãƒ³ãƒˆ**:  
  * base_retriever = vectorstore.as_retriever(search_kwargs={"k": 5}): æœ€åˆã®æ¤œç´¢ã§ã¯ã€å°‘ã—å¤šã‚ã®5ä»¶ã‚’å–å¾—ã™ã‚‹ã‚ˆã†ã«è¨­å®šã—ã¾ã™ã€‚  
  * HuggingFaceCrossEncoder: ãƒªãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’è¡Œã†ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã‚’Hugging Faceã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã™ã€‚ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã¯ã€è³ªå•ã¨æ–‡æ›¸ã‚’ãƒšã‚¢ã§å…¥åŠ›ã™ã‚‹ãŸã‚ã€å˜ç´”ãªãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚ˆã‚Šé«˜ç²¾åº¦ãªé–¢é€£åº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—ã§ãã¾ã™ã€‚  
  * CrossEncoderReranker: èª­ã¿è¾¼ã‚“ã ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã€å®Ÿéš›ã«ä¸¦ã¹æ›¿ãˆã‚’è¡Œã†ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã™ã€‚top_n=3ã§ã€æœ€çµ‚çš„ã«ä¸Šä½3ä»¶ã®æ–‡æ›¸ã ã‘ã‚’æ®‹ã™ã‚ˆã†ã«æŒ‡å®šã—ã¦ã„ã¾ã™ã€‚  
  * ContextualCompressionRetriever: ã“ã®ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ãŒã€ãƒ™ãƒ¼ã‚¹ã¨ãªã‚‹ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼ã¨ãƒªãƒ©ãƒ³ã‚«ãƒ¼ã‚’çµ„ã¿åˆã‚ã›ã‚‹å½¹å‰²ã‚’æœãŸã—ã¾ã™ã€‚

#### **ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ (reranking_rag.py)**
```
import os  
from dotenv import load_dotenv  
from langchain_openai import ChatOpenAI  
from langchain_community.embeddings import HuggingFaceEmbeddings  
from langchain_community.document_loaders import TextLoader  
from langchain.text_splitter import RecursiveCharacterTextSplitter  
from langchain_community.vectorstores import Chroma  
from langchain.chains import RetrievalQA  
from langchain.retrievers import ContextualCompressionRetriever  
from langchain.retrievers.document_compressors import CrossEncoderReranker  
from langchain_community.cross_encoders import HuggingFaceCrossEncoder

def main():  
    # --- æº–å‚™ ---  
    load_dotenv()  
    openrouter_api_key = os.getenv("OPENROUTER_API_KEY")  
    if not openrouter_api_key:  
        print("OPENROUTER_API_KEYãŒ.envãƒ•ã‚¡ã‚¤ãƒ«ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")  
        return  
    print(f"èª­ã¿è¾¼ã¾ã‚ŒãŸOpenRouter APIã‚­ãƒ¼ã®æœ«å°¾5æ–‡å­—: ...{openrouter_api_key[-5:]}")  
      
    llm = ChatOpenAI(model="google/gemma-3-12b-it:free", temperature=0, base_url="https://openrouter.ai/api/v1", api_key=openrouter_api_key)  
    embeddings = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")

    loader = TextLoader("gemini_document.txt", encoding="utf-8")  
    documents = loader.load()  
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)  
    texts = text_splitter.split_documents(documents)  
    vectorstore = Chroma.from_documents(texts, embeddings)

    # --- Re-rankingã‚’ä½¿ã£ãŸQAãƒã‚§ãƒ¼ãƒ³ã®æ§‹ç¯‰ ---  
    base_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})  
    model = HuggingFaceCrossEncoder(model_name="cross-encoder/ms-marco-MiniLM-L-6-v2")  
    compressor = CrossEncoderReranker(model=model, top_n=3)  
    compression_retriever = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=base_retriever)  
    qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=compression_retriever)

    # --- å®Ÿè¡Œ ---  
    question = "é–‹ç™ºè€…ã¯ã©ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ã¦ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æ§‹ç¯‰ã§ãã¾ã™ã‹ï¼Ÿ"  
    print(f"\nè³ªå•: {question}")  
    response = qa_chain.invoke(question)  
    print(f"å›ç­”: {response['result']}")

if __name__ == "__main__":  
    main()
```
## **5. ã¾ã¨ã‚**

ä»Šå›ã¯ã€RAGã®æ¤œç´¢ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ã€3ã¤ã®é«˜åº¦ãªæ¤œç´¢æ‰‹æ³•ã‚’å­¦ã³ã¾ã—ãŸã€‚

| ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ | æ¦‚è¦ | ç‰¹ã«æœ‰åŠ¹ãªã‚±ãƒ¼ã‚¹ |
| :---- | :---- | :---- |
| **Multi-Query Retriever** | è³ªå•ã‚’è¤‡æ•°ã®è¦–ç‚¹ã‹ã‚‰å†ç”Ÿæˆã—ã¦æ¤œç´¢ | è³ªå•ãŒæ›–æ˜§ãªå ´åˆã€æ¤œç´¢æ¼ã‚Œã‚’é˜²ããŸã„å ´åˆ |
| **Hybrid Search** | ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã¨ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’çµ„ã¿åˆã‚ã›ã‚‹ | å›ºæœ‰åè©ã‚„å°‚é–€ç”¨èªãŒé‡è¦ãªå ´åˆ |
| **Re-ranking** | ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã§å–å¾—æ–‡æ›¸ã‚’å†è©•ä¾¡ã—ä¸¦ã¹æ›¿ãˆ | æ¤œç´¢çµæœã«ãƒã‚¤ã‚ºãŒå¤šã„å ´åˆã€LLMã¸ã®å…¥åŠ›ã‚’æœ€é©åŒ–ã—ãŸã„å ´åˆ |

ã“ã‚Œã‚‰ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã¯ã€ã©ã‚Œã‹ä¸€ã¤ã ã‘ãŒå„ªã‚Œã¦ã„ã‚‹ã¨ã„ã†ã‚ã‘ã§ã¯ãªãã€ãã‚Œãã‚Œã«å¾—æ„ãªçŠ¶æ³ãŒã‚ã‚Šã¾ã™ã€‚ã¾ãŸã€è¤‡æ•°ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚çš†ã•ã‚“ãŒRAGã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹ç™ºã™ã‚‹éš›ã«ã¯ã€ãœã²ã“ã‚Œã‚‰ã®ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’è©¦ã—ã€è‡ªåˆ†ã®èª²é¡Œã«æœ€ã‚‚é©ã—ãŸæ‰‹æ³•ã‚’è¦‹ã¤ã‘ã¦ãã ã•ã„ã€‚

æœ¬æ—¥ã®æˆæ¥­ã¯ä»¥ä¸Šã§ã™ã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸï¼