# **OpenRouter入門：多様なLLMを使いこなす**

この資料では、様々な大規模言語モデル（LLM）を統一された方法で利用できるサービス「OpenRouter」について解説します。OpenRouterを使いこなすことで、特定の企業のモデルに縛られることなく、プロジェクトの要件に最適なモデルを柔軟に選択・利用できるようになります。

## **1. OpenRouterとは？**

OpenRouterは、GPTシリーズ、Claudeシリーズ、Llama、Mistralなど、数多くのLLMや画像生成AIに単一のAPIからアクセスできるようにする仲介サービス（アグリゲーター）です。

### **OpenRouterの主なメリット**

* **多様なモデルへのアクセス**: 1つのAPIキーで、商用モデルからオープンソースモデルまで、100種類以上のモデルを試すことができます。  
* **シンプルな料金体系**: モデルごとに個別の契約は不要です。OpenRouterに対して利用した分だけ支払う、従量課金制です。  
* **コストの最適化**: モデルごとの料金が明確に提示されており、性能とコストを比較検討しながら最適なモデルを選択できます。一部のモデルは、公式から直接利用するよりも安価な場合があります。  
* **OpenAI互換のAPIによる簡単な移行**: 多くの開発者が使い慣れたOpenAIのAPIと互換性のある形式を採用しています。そのため、openaiライブラリをそのまま利用でき、APIのエンドポイントURL（base_url）を変更するだけで、既存のアプリケーションを簡単にOpenRouterに接続できます。

### **1.1. サービスプロバイダの役割の違い**

LLMを利用するためのサービスを提供している企業は、その役割によって大きく2種類に分けられます。これを理解することで、OpenRouterのようなサービスの価値がより明確になります。

* **モデル開発元（メーカー）**  
  * **概要**: OpenAI、Anthropic、Googleのように、LLMそのものを研究・開発している企業や組織です。彼らはAIモデルの「製造元」と言えます。  
  * **ビジネス**: 自社で開発した最新・高性能なモデルを、独自のAPIサービスとして提供し、収益を得ています。モデルの品質や性能に関する一次情報の発信源でもあります。  
  * **例**:  
    * **OpenAI**: GPTシリーズを開発し、OpenAI APIを通じて提供。  
    * **Anthropic**: Claudeシリーズを開発し、Anthropic APIを通じて提供。  
* **アグリゲーター（総合商社 / マーケットプレイス）**  
  * **概要**: OpenRouterのように、他社が開発した様々なモデル（開発元のモデルやオープンソースモデル）を集約し、統一された形式で利用できるプラットフォームを提供するサービスです。彼らはLLMの「総合商社」や「マーケットプレイス」のような存在です。  
  * **ビジネス**: 利用者にとっては、**「1つの契約と1つのAPIキーで、あらゆるモデルにアクセスできる」**という利便性を提供することで価値を生み出します。各開発元と個別に契約する手間を省き、料金体系を一本化します。また、オープンソースモデルを自社のインフラでホスティングし、手軽に使えるようにしています。  
  * **例**:  
    * **OpenRouter**: 多数の開発元APIと接続し、さらにオープンソースモデルもホスティングして、単一のAPIで提供。  
    * **Together AI**, **Fireworks AI**: オープンソースモデルの高速なAPI実行に特化したサービス。  
    * **Amazon Bedrock**, **Google Cloud Vertex AI**: 大手クラウドサービスが提供する統合AIプラットフォーム。自社モデルに加えて、Anthropicなど他社のモデルも利用可能。

この違いを理解することで、なぜ同じモデル（例: Llama 3）が複数のプロバイダから提供されているのか、そして「多くのモデルを比較検討したい」「開発元の切り替えを柔軟に行いたい」といったニーズに対して、OpenRouterのようなアグリゲーターが非常に強力な選択肢となる理由がわかります。

## **2. 無料アカウントの作成とAPIキーの取得**

まず、OpenRouterを利用するためのアカウントを作成します。

### **手順**

1. **公式サイトにアクセス**: [https://openrouter.ai/](https://openrouter.ai/) にアクセスします。  
2. **サインイン**: 右上の「Sign In」ボタンをクリックします。GoogleアカウントやEメールで簡単にサインアップできます。  
3. **無料クレジット**: 新規登録すると、少額の無料クレジットが付与されます。このクレジットの範囲内で、APIを無料で試すことができます。  
4. **APIキーの取得**:  
   * サインイン後、右上のアカウントアイコンをクリックし、「Keys」を選択します。  
   * 「+ Create Key」ボタンをクリックして、新しいAPIキーに名前を付け（例: my-llm-class-key）、作成します。  
   * **重要**: 作成されたAPIキーは一度しか表示されません。必ずコピーして、安全な場所に保管してください。このAPIキーが、外部のプログラムからOpenRouterを利用する際の「鍵」になります。

## **3. OpenRouterの基本的な使い方（Webインターフェース）**

APIをプログラムから利用する前に、Webサイト上で様々なモデルを試してみましょう。

1. **モデルの選択（無料・有料）**:  
   * OpenRouterのトップページにあるチャット画面で、モデル名が表示されている部分（デフォルトでは Sonnet 3.5 など）をクリックします。  
   * 利用可能なモデルのリストが表示されます。各モデルには料金が設定されています。  
   * **有料モデル**: ほとんどのモデルには、入力と出力のコスト（$/1M tokens = 100万トークンあたりのドル価格）が記載されています。これらを利用するためには、OpenRouterアカウントにクレジットをチャージする必要があります。  
   * **無料モデル**: 一部のモデルには Free というラベルが付いており、クレジットを消費せずに無制限で利用できます。学習や実験に最適です。  
   * 試したいモデルを選択します。  
2. **チャットで試す**:  
   * モデルを選択したら、下部の入力ボックスにプロンプト（指示文）を入力して、AIとの対話を試すことができます。  
   * これにより、各モデルの応答の速さ、賢さ、創造性などの特徴を直感的に把握できます。

## **4. PythonからAPIを呼び出す**

ここからは、PythonプログラムからOpenRouterのAPIを利用する方法を解説します。

OpenRouterの大きな特徴は、**OpenAIのAPIと互換性がある**ことです。これにより、私たちは使い慣れたopenaiライブラリをそのまま使用できます。実際にOpenAIのAPIを呼び出すコードとの主な違いは、クライアントを初期化する際にbase_urlをOpenRouterのエンドポイント（https://openrouter.ai/api/v1）に指定する点だけです。

以下のコードは、指定したモデルにリクエストを送り、応答を受け取る基本的なサンプルです。
```python
# 必要なライブラリをインストールします  
# pip install openai

import os  
from openai import OpenAI

# 1. APIキーの設定  
# 以下の `api_key` にあなたのOpenRouter APIキーを直接貼り付けます。  
#【重要】この方法は簡単ですが、コードを他者と共有する場合（例: GitHub）は、  
# APIキーが漏洩する危険性があるため非推奨です。  
# その場合は、コメントアウトされている環境変数を利用する方法が安全です。  
api_key = "sk-or-v1-ここにあなたのAPIキーを貼り付けてください"

# --- 推奨される方法（環境変数を利用） ---  
# api_key = os.getenv("OPENROUTER_API_KEY")  
# if not api_key:  
#     raise ValueError("APIキーが設定されていません。環境変数 OPENROUTER_API_KEY を設定してください。")  
# -----------------------------------------

# 2. OpenAIクライアントの初期化  
# OpenRouterを利用するために、いくつかの設定を変更します。  
client = OpenAI(  
    # OpenRouterのAPIキーを渡します  
    api_key=api_key,  
    # OpenRouterのエンドポイントURLを指定します  
    base_url="https://openrouter.ai/api/v1",  
)

# 3. 使用するモデルの指定  
# OpenRouterのサイトで使いたいモデルの「Model Name」を確認して指定します。  
# この例では、無料で利用できる `google/gemma-3-27b-it:free` を使用します。  
model_name = "google/gemma-3-27b-it:free"

print(f"モデル '{model_name}' を使用してリクエストを送信します...")

try:  
    # 4. チャット補完（Chat Completion）の実行  
    # ここでLLMにリクエストを送信します。  
    completion = client.chat.completions.create(  
      # messages: ユーザーからの質問や指示をリスト形式で渡します。  
      messages=[  
        {  
          "role": "system",  
          "content": "あなたは親切で優秀なアシスタントです。",  
        },  
        {  
          "role": "user",  
          "content": "日本で一番高い山について、その標高と名前を教えてください。",  
        },  
      ],  
      # model: 使用するモデル名を指定します。  
      model=model_name,  
      # stream: Falseにすると、全ての応答が完了してから結果を受け取ります。  
      stream=False,  
    )

    # 5. 結果の表示  
    # 応答メッセージは `completion.choices[0].message.content` に格納されています。  
    response_message = completion.choices[0].message.content  
    print("\nAIからの応答:")  
    print(response_message)

    # 参考: 消費したトークン数などの情報も取得できます  
    print("\n--- 利用情報 ---")  
    print(f"使用トークン数: {completion.usage.total_tokens}")  
    print(f"完了理由: {completion.choices[0].finish_reason}")

except Exception as e:  
    print(f"エラーが発生しました: {e}")  
```
